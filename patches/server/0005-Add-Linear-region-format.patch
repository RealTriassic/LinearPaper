From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Triassic <techbyteofficial9@gmail.com>
Date: Sat, 23 Sep 2023 01:18:14 +0300
Subject: [PATCH] Add Linear region format


diff --git a/build.gradle.kts b/build.gradle.kts
index 1cd5099c3643d85f1148aa0f439808a3b476cdae..ce7b3544e670551ccc02e090d7c25b8370731171 100644
--- a/build.gradle.kts
+++ b/build.gradle.kts
@@ -30,6 +30,10 @@ dependencies {
     alsoShade(log4jPlugins.output)
     implementation("io.netty:netty-codec-haproxy:4.1.97.Final") // Paper - Add support for proxy protocol
     // Paper end
+    // LinearPaper start
+    implementation("com.github.luben:zstd-jni:1.5.6-3")
+    implementation("org.lz4:lz4-java:1.8.0")
+    // LinearPaper end
     implementation("org.apache.logging.log4j:log4j-iostreams:2.22.1") // Paper - remove exclusion
     implementation("org.ow2.asm:asm-commons:9.7")
     implementation("org.spongepowered:configurate-yaml:4.2.0-SNAPSHOT") // Paper - config files
diff --git a/src/main/java/net/minecraft/util/worldupdate/WorldUpgrader.java b/src/main/java/net/minecraft/util/worldupdate/WorldUpgrader.java
index fdbae0c9300e2e47147d0e1eb2a108de92c8d588..71e1b030d226315bf4b4d79532130d3928c81585 100644
--- a/src/main/java/net/minecraft/util/worldupdate/WorldUpgrader.java
+++ b/src/main/java/net/minecraft/util/worldupdate/WorldUpgrader.java
@@ -76,7 +76,7 @@ public class WorldUpgrader {
     volatile int skipped;
     final Reference2FloatMap<ResourceKey<Level>> progressMap = Reference2FloatMaps.synchronize(new Reference2FloatOpenHashMap());
     volatile Component status = Component.translatable("optimizeWorld.stage.counting");
-    static final Pattern REGEX = Pattern.compile("^r\\.(-?[0-9]+)\\.(-?[0-9]+)\\.mca$");
+    static final Pattern REGEX = Pattern.compile("^r\\.(-?[0-9]+)\\.(-?[0-9]+)\\.(linear | mca)$"); // LinearPaper
     final DimensionDataStorage overworldDataStorage;
 
     public WorldUpgrader(LevelStorageSource.LevelStorageAccess session, DataFixer dataFixer, RegistryAccess dynamicRegistryManager, boolean eraseCache, boolean recreateRegionFiles) {
@@ -406,7 +406,7 @@ public class WorldUpgrader {
 
         private static List<WorldUpgrader.FileToUpgrade> getAllChunkPositions(RegionStorageInfo key, Path regionDirectory) {
             File[] afile = regionDirectory.toFile().listFiles((file, s) -> {
-                return s.endsWith(".mca");
+                return s.endsWith(".linear") || s.endsWith(".mca"); // LinearPaper
             });
 
             if (afile == null) {
diff --git a/src/main/java/net/minecraft/world/level/chunk/storage/RegionFileStorage.java b/src/main/java/net/minecraft/world/level/chunk/storage/RegionFileStorage.java
index 37342b281bf9595f21cc0fb2e6f8ab0011cbc348..5e2668ced9aa7ad1d4ab09f55cd009b4ec335f89 100644
--- a/src/main/java/net/minecraft/world/level/chunk/storage/RegionFileStorage.java
+++ b/src/main/java/net/minecraft/world/level/chunk/storage/RegionFileStorage.java
@@ -72,7 +72,7 @@ public class RegionFileStorage implements AutoCloseable {
     @Nullable
     public static ChunkPos getRegionFileCoordinates(Path file) {
         String fileName = file.getFileName().toString();
-        if (!fileName.startsWith("r.") || !fileName.endsWith(".mca")) {
+        if (!fileName.startsWith("r.") || !fileName.endsWith(".linear") || !fileName.endsWith(".mca")) { // LinearPaper
             return null;
         }
 
@@ -133,11 +133,20 @@ public class RegionFileStorage implements AutoCloseable {
             // Paper - only create directory if not existing only - moved down
             Path path = this.folder;
             int j = chunkcoordintpair.getRegionX();
-            Path path1 = path.resolve("r." + j + "." + chunkcoordintpair.getRegionZ() + ".mca"); // Paper - diff on change
-            if (existingOnly && !java.nio.file.Files.exists(path1)) { // Paper start - cache regionfile does not exist state
-                this.markNonExisting(regionPos);
-                return null; // CraftBukkit
+            // LinearPaper start
+            Path path1;
+            if (existingOnly) {
+                Path linear = path.resolve("r." + j + "." + chunkcoordintpair.getRegionZ() + ".linear");
+                Path anvil = path.resolve("r." + j + "." + chunkcoordintpair.getRegionZ() + ".mca");
+                path1 = java.nio.file.Files.exists(linear) ? linear : java.nio.file.Files.exists(anvil) ? anvil : null;
+                if (path1 == null) {
+                    this.markNonExisting(regionPos);
+                    return null; // CraftBukkit
+                }
             } else {
+                String extension = this.info.regionFormat() == org.stupidcraft.linearpaper.region.RegionFileFormat.LINEAR ? "linear" : "mca";
+                path1 = path.resolve("r." + j + "." + chunkcoordintpair.getRegionZ() + "." + extension);
+                // LinearPaper end
                 this.createRegionFile(regionPos);
             }
             // Paper end - cache regionfile does not exist state
diff --git a/src/main/java/net/minecraft/world/level/chunk/storage/RegionStorageInfo.java b/src/main/java/net/minecraft/world/level/chunk/storage/RegionStorageInfo.java
index 6111631c6673948b266286894603cc5e30451b02..a17428f1fb14adf865f3a8edd24bd5d5444087ca 100644
--- a/src/main/java/net/minecraft/world/level/chunk/storage/RegionStorageInfo.java
+++ b/src/main/java/net/minecraft/world/level/chunk/storage/RegionStorageInfo.java
@@ -7,4 +7,20 @@ public record RegionStorageInfo(String level, ResourceKey<Level> dimension, Stri
     public RegionStorageInfo withTypeSuffix(String suffix) {
         return new RegionStorageInfo(this.level, this.dimension, this.type + suffix);
     }
+
+    // LinearPaper start
+    public org.stupidcraft.linearpaper.region.RegionFileFormat regionFormat() {
+        return ((org.bukkit.craftbukkit.CraftWorld) org.bukkit.Bukkit.getWorld(level))
+            .getHandle()
+            .linearConfig
+            .regionFormat;
+    }
+
+    public int linearCompressionLevel() {
+        return ((org.bukkit.craftbukkit.CraftWorld) org.bukkit.Bukkit.getWorld(level))
+            .getHandle()
+            .linearConfig
+            .linearCompressionLevel;
+    }
+    // LinearPaper end
 }
diff --git a/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFileFactory.java b/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFileFactory.java
index a2ac8e822564ce0bc903c902aa5566afdc400314..28cd1b1b4bd60596f6439208feacbff97bd84161 100644
--- a/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFileFactory.java
+++ b/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFileFactory.java
@@ -20,6 +20,10 @@ public class AbstractRegionFileFactory {
     }
 
     public static AbstractRegionFile getAbstractRegionFile(RegionStorageInfo storageKey, Path path, Path directory, RegionFileVersion compressionFormat, boolean dsync, boolean canRecalcHeader) throws IOException {
-        return new RegionFile(storageKey, path, directory, compressionFormat, dsync, canRecalcHeader);
+        if (path.toString().endsWith(".linear")) {
+            return new LinearRegionFile(path, storageKey.linearCompressionLevel());
+        } else {
+            return new RegionFile(storageKey, path, directory, compressionFormat, dsync, canRecalcHeader);
+        }
     }
 }
diff --git a/src/main/java/org/stupidcraft/linearpaper/region/LinearRegionFile.java b/src/main/java/org/stupidcraft/linearpaper/region/LinearRegionFile.java
new file mode 100644
index 0000000000000000000000000000000000000000..6df6847721003c18647f8dc8d4e4b10d537bce0c
--- /dev/null
+++ b/src/main/java/org/stupidcraft/linearpaper/region/LinearRegionFile.java
@@ -0,0 +1,319 @@
+package org.stupidcraft.linearpaper.region;
+
+import com.github.luben.zstd.ZstdInputStream;
+import com.github.luben.zstd.ZstdOutputStream;
+import com.mojang.logging.LogUtils;
+import java.io.BufferedOutputStream;
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.ByteBuffer;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardCopyOption;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.locks.ReentrantLock;
+import javax.annotation.Nullable;
+import net.jpountz.lz4.LZ4Compressor;
+import net.jpountz.lz4.LZ4Factory;
+import net.jpountz.lz4.LZ4FastDecompressor;
+import net.minecraft.nbt.CompoundTag;
+import net.minecraft.world.level.ChunkPos;
+import net.minecraft.world.level.chunk.status.ChunkStatus;
+import org.slf4j.Logger;
+
+public class LinearRegionFile implements AbstractRegionFile, AutoCloseable {
+    private static final long SUPERBLOCK = -4323716122432332390L;
+    private static final byte VERSION = 2;
+    private static final int HEADER_SIZE = 32;
+    private static final int FOOTER_SIZE = 8;
+    private static final Logger LOGGER = LogUtils.getLogger();
+    private static final List<Byte> SUPPORTED_VERSIONS = Arrays.asList((byte) 1, (byte) 2);
+    private static final LinearRegionFileFlusher linearRegionFileFlusher = new LinearRegionFileFlusher();
+    public final ReentrantLock fileLock = new ReentrantLock(true);
+    private final byte[][] buffer = new byte[1024][];
+    private final int[] bufferUncompressedSize = new int[1024];
+    private final int[] chunkTimestamps = new int[1024];
+    private final ChunkStatus[] statuses = new ChunkStatus[1024];
+    private final LZ4Compressor compressor;
+    private final LZ4FastDecompressor decompressor;
+    private final int compressionLevel;
+    public boolean closed = false;
+    public Path path;
+    private final AtomicBoolean markedToSave = new AtomicBoolean(false);
+
+
+    public LinearRegionFile(Path file, int compression) throws IOException {
+        this.path = file;
+        this.compressionLevel = compression;
+        this.compressor = LZ4Factory.fastestInstance().fastCompressor();
+        this.decompressor = LZ4Factory.fastestInstance().fastDecompressor();
+
+        File regionFile = new File(this.path.toString());
+
+        Arrays.fill(this.bufferUncompressedSize, 0);
+
+        if (!regionFile.canRead()) return;
+
+        try (FileInputStream fileStream = new FileInputStream(regionFile);
+             DataInputStream rawDataStream = new DataInputStream(fileStream)) {
+
+            long superBlock = rawDataStream.readLong();
+            if (superBlock != SUPERBLOCK)
+                throw new RuntimeException("Invalid superblock: " + superBlock + " in " + file);
+
+            byte version = rawDataStream.readByte();
+            if (!SUPPORTED_VERSIONS.contains(version))
+                throw new RuntimeException("Invalid version: " + version + " in " + file);
+
+            // Skip newestTimestamp (Long) + Compression level (Byte) + Chunk count (Short): Unused.
+            rawDataStream.skipBytes(11);
+
+            int dataCount = rawDataStream.readInt();
+            long fileLength = file.toFile().length();
+            if (fileLength != HEADER_SIZE + dataCount + FOOTER_SIZE)
+                throw new IOException("Invalid file length: " + this.path + " " + fileLength + " " + (HEADER_SIZE + dataCount + FOOTER_SIZE));
+
+            rawDataStream.skipBytes(8); // Skip data hash (Long): Unused.
+
+            byte[] rawCompressed = new byte[dataCount];
+            rawDataStream.readFully(rawCompressed, 0, dataCount);
+
+            superBlock = rawDataStream.readLong();
+            if (superBlock != SUPERBLOCK)
+                throw new IOException("Footer superblock invalid " + this.path);
+
+            try (DataInputStream dataStream = new DataInputStream(new ZstdInputStream(new ByteArrayInputStream(rawCompressed)))) {
+
+                int[] starts = new int[1024];
+                for (int i = 0; i < 1024; i++) {
+                    starts[i] = dataStream.readInt();
+                    dataStream.skipBytes(4); // Skip timestamps (Int): Unused.
+                }
+
+                for (int i = 0; i < 1024; i++) {
+                    if (starts[i] > 0) {
+                        int size = starts[i];
+                        byte[] b = new byte[size];
+                        dataStream.readFully(b, 0, size);
+
+                        int maxCompressedLength = this.compressor.maxCompressedLength(size);
+                        byte[] compressed = new byte[maxCompressedLength];
+                        int compressedLength = this.compressor.compress(b, 0, size, compressed, 0, maxCompressedLength);
+                        b = new byte[compressedLength];
+                        System.arraycopy(compressed, 0, b, 0, compressedLength);
+
+                        this.buffer[i] = b;
+                        this.bufferUncompressedSize[i] = size;
+                    }
+                }
+            }
+        }
+    }
+
+    private static int getChunkIndex(int x, int z) {
+        return (x & 31) + ((z & 31) << 5);
+    }
+
+    private static int getTimestamp() {
+        return (int) (System.currentTimeMillis() / 1000L);
+    }
+
+    public Path getRegionFile() {
+        return this.path;
+    }
+
+    public ReentrantLock getFileLock() {
+        return this.fileLock;
+    }
+
+    public void flush() throws IOException {
+        if (isMarkedToSave()) flushWrapper(); // sync
+    }
+
+    private void markToSave() {
+        linearRegionFileFlusher.scheduleSave(this);
+        markedToSave.set(true);
+    }
+
+    public boolean isMarkedToSave() {
+        return markedToSave.getAndSet(false);
+    }
+
+    public void flushWrapper() {
+        try {
+            save();
+        } catch (IOException e) {
+            LOGGER.error("Failed to flush region file " + path.toAbsolutePath(), e);
+        }
+    }
+
+    public boolean doesChunkExist(ChunkPos pos) throws Exception {
+        throw new Exception("doesChunkExist is a stub");
+    }
+
+    private synchronized void save() throws IOException {
+        long timestamp = getTimestamp();
+        short chunkCount = 0;
+
+        File tempFile = new File(path.toString() + ".tmp");
+
+        try (FileOutputStream fileStream = new FileOutputStream(tempFile);
+             ByteArrayOutputStream zstdByteArray = new ByteArrayOutputStream();
+             ZstdOutputStream zstdStream = new ZstdOutputStream(zstdByteArray, this.compressionLevel);
+             DataOutputStream zstdDataStream = new DataOutputStream(zstdStream);
+             DataOutputStream dataStream = new DataOutputStream(fileStream)) {
+
+            dataStream.writeLong(SUPERBLOCK);
+            dataStream.writeByte(VERSION);
+            dataStream.writeLong(timestamp);
+            dataStream.writeByte(this.compressionLevel);
+
+            ArrayList<byte[]> byteBuffers = new ArrayList<>();
+            for (int i = 0; i < 1024; i++) {
+                if (this.bufferUncompressedSize[i] != 0) {
+                    chunkCount += 1;
+                    byte[] content = new byte[bufferUncompressedSize[i]];
+                    this.decompressor.decompress(buffer[i], 0, content, 0, bufferUncompressedSize[i]);
+
+                    byteBuffers.add(content);
+                } else byteBuffers.add(null);
+            }
+            for (int i = 0; i < 1024; i++) {
+                zstdDataStream.writeInt(this.bufferUncompressedSize[i]); // Write uncompressed size
+                zstdDataStream.writeInt(this.chunkTimestamps[i]); // Write timestamp
+            }
+            for (int i = 0; i < 1024; i++) {
+                if (byteBuffers.get(i) != null)
+                    zstdDataStream.write(byteBuffers.get(i), 0, byteBuffers.get(i).length);
+            }
+            zstdDataStream.close();
+
+            dataStream.writeShort(chunkCount);
+
+            byte[] compressed = zstdByteArray.toByteArray();
+
+            dataStream.writeInt(compressed.length);
+            dataStream.writeLong(0);
+
+            dataStream.write(compressed, 0, compressed.length);
+            dataStream.writeLong(SUPERBLOCK);
+
+            dataStream.flush();
+            fileStream.getFD().sync();
+            fileStream.getChannel().force(true); // Ensure atomicity on Btrfs
+        }
+        Files.move(tempFile.toPath(), this.path, StandardCopyOption.REPLACE_EXISTING);
+    }
+
+    public void setStatus(int x, int z, ChunkStatus status) {
+        this.statuses[getChunkIndex(x, z)] = status;
+    }
+
+    public synchronized void write(ChunkPos pos, ByteBuffer buffer) {
+        try {
+            byte[] b = toByteArray(new ByteArrayInputStream(buffer.array()));
+            int uncompressedSize = b.length;
+
+            int maxCompressedLength = this.compressor.maxCompressedLength(b.length);
+            byte[] compressed = new byte[maxCompressedLength];
+            int compressedLength = this.compressor.compress(b, 0, b.length, compressed, 0, maxCompressedLength);
+            b = new byte[compressedLength];
+            System.arraycopy(compressed, 0, b, 0, compressedLength);
+
+            int index = getChunkIndex(pos.x, pos.z);
+            this.buffer[index] = b;
+            this.chunkTimestamps[index] = getTimestamp();
+            this.bufferUncompressedSize[getChunkIndex(pos.x, pos.z)] = uncompressedSize;
+        } catch (IOException e) {
+            LOGGER.error("Chunk write IOException " + e + " " + this.path);
+        }
+        markToSave();
+    }
+
+    public DataOutputStream getChunkDataOutputStream(ChunkPos pos) {
+        return new DataOutputStream(new BufferedOutputStream(new ChunkBuffer(pos)));
+    }
+
+    private byte[] toByteArray(InputStream in) throws IOException {
+        ByteArrayOutputStream out = new ByteArrayOutputStream();
+        byte[] tempBuffer = new byte[4096];
+
+        int length;
+        while ((length = in.read(tempBuffer)) >= 0) {
+            out.write(tempBuffer, 0, length);
+        }
+
+        return out.toByteArray();
+    }
+
+    @Nullable
+    public synchronized DataInputStream getChunkDataInputStream(ChunkPos pos) {
+        if (this.bufferUncompressedSize[getChunkIndex(pos.x, pos.z)] != 0) {
+            byte[] content = new byte[bufferUncompressedSize[getChunkIndex(pos.x, pos.z)]];
+            this.decompressor.decompress(this.buffer[getChunkIndex(pos.x, pos.z)], 0, content, 0, bufferUncompressedSize[getChunkIndex(pos.x, pos.z)]);
+            return new DataInputStream(new ByteArrayInputStream(content));
+        }
+        return null;
+    }
+
+    public ChunkStatus getStatusIfCached(int x, int z) {
+        return this.statuses[getChunkIndex(x, z)];
+    }
+
+    public void clear(ChunkPos pos) {
+        int i = getChunkIndex(pos.x, pos.z);
+        this.buffer[i] = null;
+        this.bufferUncompressedSize[i] = 0;
+        this.chunkTimestamps[i] = getTimestamp();
+        markToSave();
+    }
+
+    public boolean hasChunk(ChunkPos pos) {
+        return this.bufferUncompressedSize[getChunkIndex(pos.x, pos.z)] > 0;
+    }
+
+    public void close() throws IOException {
+        if (closed) return;
+        closed = true;
+        flush(); // sync
+    }
+
+    public boolean recalculateHeader() {
+        return false;
+    }
+
+    public void setOversized(int x, int z, boolean something) {
+    }
+
+    public CompoundTag getOversizedData(int x, int z) throws IOException {
+        throw new IOException("getOversizedData is a stub " + this.path);
+    }
+
+    public boolean isOversized(int x, int z) {
+        return false;
+    }
+
+    private class ChunkBuffer extends ByteArrayOutputStream {
+        private final ChunkPos pos;
+
+        public ChunkBuffer(ChunkPos chunkcoordintpair) {
+            super();
+            this.pos = chunkcoordintpair;
+        }
+
+        public void close() throws IOException {
+            ByteBuffer bytebuffer = ByteBuffer.wrap(this.buf, 0, this.count);
+            LinearRegionFile.this.write(this.pos, bytebuffer);
+        }
+    }
+}
diff --git a/src/main/java/org/stupidcraft/linearpaper/region/LinearRegionFileFlusher.java b/src/main/java/org/stupidcraft/linearpaper/region/LinearRegionFileFlusher.java
new file mode 100644
index 0000000000000000000000000000000000000000..11c5dbdc855df513242e57e198aa0d752a781c80
--- /dev/null
+++ b/src/main/java/org/stupidcraft/linearpaper/region/LinearRegionFileFlusher.java
@@ -0,0 +1,49 @@
+package org.stupidcraft.linearpaper.region;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+import java.util.Queue;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import org.bukkit.Bukkit;
+import org.stupidcraft.linearpaper.LinearConfig;
+
+public class LinearRegionFileFlusher {
+    private final Queue<LinearRegionFile> savingQueue = new LinkedBlockingQueue<>();
+    private final ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor(
+        new ThreadFactoryBuilder()
+            .setNameFormat("linear-flush-scheduler")
+            .build()
+    );
+    private final ExecutorService executor = Executors.newFixedThreadPool(
+        LinearConfig.linearFlushThreads,
+        new ThreadFactoryBuilder()
+            .setNameFormat("linear-flusher-%d")
+            .build()
+    );
+
+    public LinearRegionFileFlusher() {
+        Bukkit.getLogger().info("Using " + LinearConfig.linearFlushThreads + " threads for linear region flushing.");
+        scheduler.scheduleAtFixedRate(this::pollAndFlush, 0L, LinearConfig.linearFlushFrequency, TimeUnit.SECONDS);
+    }
+
+    public void scheduleSave(LinearRegionFile regionFile) {
+        if (savingQueue.contains(regionFile)) return;
+        savingQueue.add(regionFile);
+    }
+
+    private void pollAndFlush() {
+        while (!savingQueue.isEmpty()) {
+            LinearRegionFile regionFile = savingQueue.poll();
+            if (!regionFile.closed && regionFile.isMarkedToSave())
+                executor.execute(regionFile::flushWrapper);
+        }
+    }
+
+    public void shutdown() {
+        executor.shutdown();
+        scheduler.shutdown();
+    }
+}
